{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataframe` to `DocumentArray`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lachy\\Videos\\LACHY\\SRI Repo\\bias-project-ML\\debiased_clip\\k_fold.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['gender'][i]= gender_mapper[df['gender'][i]]\n",
      "c:\\Users\\lachy\\Videos\\LACHY\\SRI Repo\\bias-project-ML\\debiased_clip\\k_fold.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['race'][i]= race_mapper[df['race'][i]]\n"
     ]
    }
   ],
   "source": [
    "from docarray import Document, DocumentArray\n",
    "import pandas\n",
    "\n",
    "from k_fold import data_selection\n",
    "\n",
    "train_df, test_df = data_selection('C:/Users/lachy/Pictures/utkface/utkface/')\n",
    "\n",
    "train_da = DocumentArray.from_dataframe(train_df)\n",
    "test_da = DocumentArray.from_dataframe(test_df)\n",
    "\n",
    "# for item in train_da:\n",
    "#     item.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing `CLIP`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CLIP` Fine-tuning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c14c5f112a4657a6edb9973d03935b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"\\n<div class='custom-container'>\\n    <style>\\n        .custom-container {\\n       â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import finetuner\n",
    "\n",
    "finetuner.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Race ` and ` Gender` Fine-tuning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ <span style=\"font-weight: bold\">Document</span>: <span style=\"color: #008080; text-decoration-color: #008080\">dd860365b746fb3269cb57857b9ef3ea</span>\n",
       "â””â”€â”€ ðŸ’  <span style=\"font-weight: bold\">Chunks</span>\n",
       "    â”œâ”€â”€ ðŸ“„ <span style=\"font-weight: bold\">Document</span>: <span style=\"color: #008080; text-decoration-color: #008080\">82a75c086d0aa1ab437ceeb0fded922c</span>\n",
       "    â”‚   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "    â”‚   â”‚<span style=\"font-weight: bold\"> Attribute </span>â”‚<span style=\"font-weight: bold\"> Value                                                            </span>â”‚\n",
       "    â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "    â”‚   â”‚ tensor    â”‚ <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'numpy.ndarray'</span><span style=\"font-weight: bold\">&gt;</span> in shape <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, dtype: uint8     â”‚\n",
       "    â”‚   â”‚ mime_type â”‚ image/jpeg                                                       â”‚\n",
       "    â”‚   â”‚ uri       â”‚ C:/Users/lachy/Pictures/utkface/utkface/100_0_0_201701122135009â€¦ â”‚\n",
       "    â”‚   â”‚ tags      â”‚ {'filename': '100_0_0_20170112213500903.jpg.chip.jpg', 'gender': â”‚\n",
       "    â”‚   â”‚           â”‚ 'male', 'race': 'white', 'filepath':                             â”‚\n",
       "    â”‚   â”‚           â”‚ 'C:/Users/lachy/Pictures/utkface/utkface/100_0_0_20170112213500â€¦ â”‚\n",
       "    â”‚   â”‚           â”‚ 'age': 100}                                                      â”‚\n",
       "    â”‚   â”‚ modality  â”‚ image                                                            â”‚\n",
       "    â”‚   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "    â””â”€â”€ ðŸ“„ <span style=\"font-weight: bold\">Document</span>: <span style=\"color: #008080; text-decoration-color: #008080\">531560819869caed81c3b2ec93010bbe</span>\n",
       "        â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "        â”‚<span style=\"font-weight: bold\"> Attribute     </span>â”‚<span style=\"font-weight: bold\"> Value                                                        </span>â”‚\n",
       "        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "        â”‚ text          â”‚ This is a person of male gender and white race.              â”‚\n",
       "        â”‚ modality      â”‚ text                                                         â”‚\n",
       "        â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ“„ \u001b[1mDocument\u001b[0m: \u001b[36mdd860365b746fb3269cb57857b9ef3ea\u001b[0m\n",
       "â””â”€â”€ ðŸ’  \u001b[1mChunks\u001b[0m\n",
       "    â”œâ”€â”€ ðŸ“„ \u001b[1mDocument\u001b[0m: \u001b[36m82a75c086d0aa1ab437ceeb0fded922c\u001b[0m\n",
       "    â”‚   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "    â”‚   â”‚\u001b[1m \u001b[0m\u001b[1mAttribute\u001b[0m\u001b[1m \u001b[0mâ”‚\u001b[1m \u001b[0m\u001b[1mValue                                                           \u001b[0m\u001b[1m \u001b[0mâ”‚\n",
       "    â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "    â”‚   â”‚ tensor    â”‚ \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'numpy.ndarray'\u001b[0m\u001b[1m>\u001b[0m in shape \u001b[1m(\u001b[0m\u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, dtype: uint8     â”‚\n",
       "    â”‚   â”‚ mime_type â”‚ image/jpeg                                                       â”‚\n",
       "    â”‚   â”‚ uri       â”‚ C:/Users/lachy/Pictures/utkface/utkface/100_0_0_201701122135009â€¦ â”‚\n",
       "    â”‚   â”‚ tags      â”‚ {'filename': '100_0_0_20170112213500903.jpg.chip.jpg', 'gender': â”‚\n",
       "    â”‚   â”‚           â”‚ 'male', 'race': 'white', 'filepath':                             â”‚\n",
       "    â”‚   â”‚           â”‚ 'C:/Users/lachy/Pictures/utkface/utkface/100_0_0_20170112213500â€¦ â”‚\n",
       "    â”‚   â”‚           â”‚ 'age': 100}                                                      â”‚\n",
       "    â”‚   â”‚ modality  â”‚ image                                                            â”‚\n",
       "    â”‚   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "    â””â”€â”€ ðŸ“„ \u001b[1mDocument\u001b[0m: \u001b[36m531560819869caed81c3b2ec93010bbe\u001b[0m\n",
       "        â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "        â”‚\u001b[1m \u001b[0m\u001b[1mAttribute    \u001b[0m\u001b[1m \u001b[0mâ”‚\u001b[1m \u001b[0m\u001b[1mValue                                                       \u001b[0m\u001b[1m \u001b[0mâ”‚\n",
       "        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "        â”‚ text          â”‚ This is a person of male gender and white race.              â”‚\n",
       "        â”‚ modality      â”‚ text                                                         â”‚\n",
       "        â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender_pairs = DocumentArray() # initialize a DocumentArray as final training data.\n",
    "\n",
    "prompt = 'This is a person of '\n",
    "for doc in train_da:\n",
    "    pair = Document()\n",
    "    doc.uri = doc.tags['filepath']\n",
    "    img_chunk = doc.load_uri_to_image_tensor(224, 224)\n",
    "    img_chunk.modality = 'image'\n",
    "    txt_chunk = Document(content=prompt + doc.tags['gender'] + ' gender and ' + doc.tags['race'] + ' race.' )\n",
    "    txt_chunk.modality = 'text'\n",
    "    pair.chunks.extend([img_chunk, txt_chunk])\n",
    "    # add pair to pairs\n",
    "    gender_pairs.append(pair)\n",
    "\n",
    "# Lets see the first item of the pairs\n",
    "gender_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18966"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gender_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training `CLIP` model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing a DocumentArray to Hubble under the name finetuner-dastorage-default-elated-easley-train ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48eb484220ec4c6b8faa4fc66b7f8aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = finetuner.fit(\n",
    "    model='openai/clip-vit-base-patch32', # fine-tune CLIP\n",
    "    train_data=gender_pairs,   \n",
    "    learning_rate=1e-5,\n",
    "    loss='CLIPLoss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in run.stream_logs():\n",
    "    print(entry)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = run.save_artifact('/artifact/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_text_encoder = finetuner.get_model(artifact=artifact, select_model='clip-text')\n",
    "clip_image_encoder = finetuner.get_model(artifact=artifact, select_model='clip-vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
